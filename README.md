# ğŸš€ ETL Pipeline avec Apache Airflow

Un projet **Data Engineering** qui dÃ©montre la maÃ®trise dâ€™Apache Airflow pour orchestrer un pipeline **ETL complet** : tÃ©lÃ©chargement, extraction multi-formats, consolidation et transformation des donnÃ©es.  
Ce dÃ©pÃ´t illustre ma capacitÃ© Ã  concevoir des workflows robustes, automatisÃ©s et rÃ©utilisables, qualitÃ©s essentielles pour un Data Engineer.

---

## ğŸ¯ Objectifs du projet
- **Automatiser** le traitement de donnÃ©es hÃ©tÃ©rogÃ¨nes (CSV, TSV, Fixed-Width).
- **Orchestrer** les tÃ¢ches avec Apache Airflow pour un pipeline fiable et maintenable.
- **Transformer** les donnÃ©es pour les rendre exploitables et prÃªtes Ã  lâ€™analyse.
- **Montrer** mes compÃ©tences pratiques en Data Engineering Ã  travers un projet concret.

---

## ğŸ› ï¸ Technologies utilisÃ©es
- **Python 3** : langage principal pour lâ€™ETL.
- **Apache Airflow** : orchestration et automatisation des tÃ¢ches.
- **Requests** : tÃ©lÃ©chargement des donnÃ©es.
- **Tarfile / CSV** : extraction et manipulation des fichiers.
- **Pendulum** : gestion des dates dans Airflow.

---
ğŸ“‚ Structure du projet

python-etl-airflow/
â”‚
â”œâ”€â”€ dags
â”‚
â”‚   â””â”€â”€ etl_toll_data.py        **Ton DAG Airflow (le code que tu as partagÃ©)**
â”‚
â”œâ”€â”€ staging                     **Dossier pour les fichiers temporaires (optionnel, peut Ãªtre ignorÃ© dans GitHub)**
â”‚
â”œâ”€â”€ requirements.txt            **DÃ©pendances Python**
â”‚
â”œâ”€â”€ README.md                   **Documentation du projet**
â”‚
â”œâ”€â”€ .gitignore                  **Fichiers Ã  ignorer (logs, staging, etc.)**
â”‚
â””â”€â”€ LICENSE                     **Licence open-source (MIT par exemple)**

## ğŸ” Explication Ã©tape par Ã©tape du pipeline

### 1ï¸âƒ£ **Download dataset**
- **MÃ©thode utilisÃ©e :** `requests.get()` avec gestion du flux et timeout.
- **But :** TÃ©lÃ©charger un fichier compressÃ© `.tgz` depuis une source externe.
---

### 2ï¸âƒ£ **Untar dataset**
- **MÃ©thode utilisÃ©e :** `tarfile.open()` pour extraire les fichiers.
- **But :** DÃ©compresser le jeu de donnÃ©es brut.
---

### 3ï¸âƒ£ **Extract data (CSV, TSV, Fixed-Width)**
- **MÃ©thodes utilisÃ©es :**
  - `csv.writer()` pour normaliser les donnÃ©es.
  - `split(',')`, `split('\t')` et slicing pour gÃ©rer diffÃ©rents formats.
- **But :** Extraire et uniformiser les donnÃ©es de trois formats distincts.
---

### 4ï¸âƒ£ **Consolidate data**
- **MÃ©thode utilisÃ©e :** `zip()` pour fusionner les lignes des trois fichiers.
- **But :** CrÃ©er un fichier unique `extracted_data.csv` regroupant toutes les informations.
 
---

### 5ï¸âƒ£ **Transform data**
- **MÃ©thode utilisÃ©e :** `csv.DictReader()` et `DictWriter()` pour manipuler les colonnes.
- **But :** Nettoyer et transformer les donnÃ©es (ex. mettre les types de vÃ©hicules en majuscules).

---

## ğŸ“Š Architecture du DAG Airflow

Download â†’ Untar â†’ [Extract CSV, Extract TSV, Extract Fixed-Width] â†’ Consolidate â†’ Transform

Chaque tÃ¢che est dÃ©finie comme un **PythonOperator** et reliÃ©e par des dÃ©pendances claires, garantissant un pipeline **fiable et reproductible**.

---

ğŸ’¡ Points forts dÃ©montrÃ©s

- Orchestration maÃ®trisÃ©e avec Airflow.

- Gestion multi-formats (CSV, TSV, Fixed-Width).

- Pipeline robuste et rÃ©utilisable grÃ¢ce aux chemins relatifs et Ã  la modularitÃ©.

- Transformation de donnÃ©es pour les rendre prÃªtes Ã  lâ€™analyse.



ğŸ‘¨â€ğŸ’» Auteur

- **Nom** : El Hadji Ablaye Galoup DIOP ğŸ“§
- **Email** : elhadjiablayegaloupdiop@gmail.com ï¿½
