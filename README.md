# ğŸš¦ Projet ETL avec Apache Airflow â€“ Analyse du trafic routier

## ğŸ“– ScÃ©nario: 

En tant quâ€™ **IngÃ©nieur de donnÃ©es** dans une sociÃ©tÃ© de conseil en analytique, jâ€™ai Ã©tÃ© chargÃ© dâ€™un projet stratÃ©gique visant Ã  **dÃ©congestionner les autoroutes nationales**. Lâ€™objectif est dâ€™analyser les donnÃ©es de trafic routier collectÃ©es Ã  partir de diffÃ©rents postes de pÃ©age. Chaque autoroute est exploitÃ©e par un opÃ©rateur distinct, avec une configuration informatique propre et des formats de fichiers hÃ©tÃ©rogÃ¨nes (CSV, TSV, Fixed-Width).  
**Ma mission** : **collecter, transformer et consolider ces donnÃ©es dans un fichier unique**, afin de les rendre exploitables pour les Ã©quipes dâ€™analystes et de dÃ©cideurs.
pour ce faire j'utilise Apache Airflow pour orchestrer un pipeline **ETL complet** : tÃ©lÃ©chargement, extraction multi-formats, consolidation et transformation des donnÃ©es.  


## ğŸ¯ Objectifs du projet
- **Centraliser** les donnÃ©es provenant de multiples sources et formats.
- **Automatiser** le pipeline de traitement de donnÃ©es hÃ©tÃ©rogÃ¨nes (CSV, TSV, Fixed-Width) grÃ¢ce Ã  Apache Airflow.
- **Orchestrer** les tÃ¢ches avec Apache Airflow pour un pipeline fiable et maintenable.
- **Normaliser et transformer** les donnÃ©es pour les rendre exploitables et prÃªtes Ã  lâ€™analyse.
- **Fournir un fichier consolidÃ©** prÃªt pour lâ€™analyse et la prise de dÃ©cision.
- **Montrer** mes compÃ©tences pratiques en Data Engineering Ã  travers un projet concret.
---

## ğŸ› ï¸ Technologies utilisÃ©es
- **Python 3** : langage principal pour lâ€™ETL.
- **Apache Airflow** : orchestration et automatisation des tÃ¢ches.
- **Requests** : tÃ©lÃ©chargement des donnÃ©es.
- **Tarfile / CSV** : extraction et manipulation des fichiers.
- **Pendulum** : gestion des dates dans Airflow.

---
ğŸ“‚ Structure du projet

python-etl-airflow

- **dags**
     - **etl_toll_data.py**   
- **staging**                     
- **requirements.txt**           
- **README.md**                  
- **.gitignore**                  
- **LICENSE**

## ğŸ” Explication Ã©tape par Ã©tape du pipeline

### 1ï¸âƒ£ **Download dataset**
- **MÃ©thode utilisÃ©e :** `requests.get()` avec gestion du flux et timeout.
- **Objectif :** TÃ©lÃ©charger un fichier compressÃ© `.tgz` depuis une source externe.
---

### 2ï¸âƒ£ **Untar dataset**
- **MÃ©thode utilisÃ©e :** `tarfile.open()` pour extraire les fichiers.
- **Objectif  :** DÃ©compresser le jeu de donnÃ©es brut.
---

### 3ï¸âƒ£ **Extract data (CSV, TSV, Fixed-Width)**
- **MÃ©thodes utilisÃ©es :**
  - `csv.writer()` pour normaliser les donnÃ©es.
  - `split(',')`, `split('\t')` et slicing pour gÃ©rer diffÃ©rents formats.
- **Objectif  :** Extraire et uniformiser les donnÃ©es de trois formats distincts.
---

### 4ï¸âƒ£ **Consolidate data**
- **MÃ©thode utilisÃ©e :** `zip()` pour fusionner les lignes des trois fichiers.
- **Objectif  :** CrÃ©er un fichier unique `extracted_data.csv` regroupant toutes les informations.
 
---

### 5ï¸âƒ£ **Transform data**
- **MÃ©thode utilisÃ©e :** `csv.DictReader()` et `DictWriter()` pour manipuler les colonnes.
- **Objectif  :** Nettoyer et transformer les donnÃ©es (ex. mettre les types de vÃ©hicules en majuscules).

---

## ğŸ“Š Architecture du DAG Airflow

Download â†’ Untar â†’ [Extract CSV, Extract TSV, Extract Fixed-Width] â†’ Consolidate â†’ Transform

Chaque tÃ¢che est dÃ©finie comme un **PythonOperator** et reliÃ©e par des dÃ©pendances claires, garantissant un pipeline **fiable et reproductible**.

---

## ğŸ“Š SchÃ©ma du pipeline ETL â€“ DAG Airflow

Voici une reprÃ©sentation visuelle du pipeline ETL orchestrÃ© avec Apache Airflow :

![DAG Pipeline](dags/dag_pipeline.png)

### ğŸ§­ LÃ©gende des Ã©tapes

- **Download Dataset** : TÃ©lÃ©charge le fichier compressÃ© contenant les donnÃ©es de pÃ©age.
- **Untar Dataset** : DÃ©compresse le fichier `.tgz` pour accÃ©der aux fichiers sources.
- **Extract CSV / TSV / Fixed-Width** : Traite les trois formats de fichiers utilisÃ©s par les diffÃ©rents opÃ©rateurs de pÃ©age.
  - `vehicle-data.csv` â†’ donnÃ©es de vÃ©hicules
  - `tollplaza-data.tsv` â†’ donnÃ©es de pÃ©age
  - `payment-data.txt` â†’ donnÃ©es de paiement
- **Consolidate Data** : Fusionne les trois sources en un fichier unique `extracted_data.csv`.
- **Transform Data** : Nettoie et transforme les donnÃ©es (ex. majuscules sur les types de vÃ©hicules) pour produire `transformed_data.csv`.

Ce DAG illustre une orchestration claire, modulaire et robuste, adaptÃ©e Ã  des environnements de production.

---

ğŸ’¼ CompÃ©tences dÃ©montrÃ©es

Ce projet mâ€™a permis de mettre en Å“uvre plusieurs compÃ©tences clÃ©s du mÃ©tier dâ€™ingÃ©nieur de donnÃ©es :

ğŸ” Orchestration de workflows avec Apache Airflow : dÃ©finition de tÃ¢ches, gestion des dÃ©pendances, planification quotidienne.

ğŸ§© Traitement multi-formats : extraction de donnÃ©es depuis des fichiers CSV, TSV et Fixed-Width, chacun issu dâ€™un systÃ¨me diffÃ©rent.

ğŸ§  Consolidation intelligente : fusion de sources hÃ©tÃ©rogÃ¨nes en un fichier unique et cohÃ©rent.

ğŸ§¹ Transformation de donnÃ©es : nettoyage, normalisation et mise en forme pour faciliter lâ€™analyse.

ğŸ› ï¸ Robustesse du code : gestion des erreurs, chemins relatifs, modularitÃ© et rÃ©utilisabilitÃ©.

ğŸ“¦ Structuration dâ€™un projet GitHub professionnel : documentation claire, schÃ©ma visuel, installation guidÃ©e.

---

ğŸ’¡ LeÃ§ons apprises

- Lâ€™importance de lâ€™automatisation : Airflow permet de fiabiliser les processus et de rÃ©duire les interventions manuelles.

- La diversitÃ© des formats de donnÃ©es : dans un contexte rÃ©el, les donnÃ©es ne sont jamais homogÃ¨nes â€” il faut savoir sâ€™adapter.

- La valeur de la clartÃ© : un code bien structurÃ© et documentÃ© est aussi important que sa performance.

- Le lien entre technique et mÃ©tier : comprendre le besoin mÃ©tier (dÃ©congestion des autoroutes) permet de mieux orienter les choix techniques.

---

**Ce dÃ©pÃ´t illustre ma capacitÃ© Ã  concevoir des workflows robustes, automatisÃ©s et rÃ©utilisables, qualitÃ©s essentielles pour un Data Engineer.**

ğŸ‘¨â€ğŸ’» Auteur

- **Nom** : El Hadji Ablaye Galoup DIOP ğŸ“§
- **Email** : elhadjiablayegaloupdiop@gmail.com ï¿½
