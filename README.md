# ğŸš€ ETL Pipeline avec Apache Airflow

Un projet **Data Engineering** qui dÃ©montre la maÃ®trise dâ€™Apache Airflow pour orchestrer un pipeline **ETL complet** : tÃ©lÃ©chargement, extraction multi-formats, consolidation et transformation des donnÃ©es.  
Ce dÃ©pÃ´t illustre ma capacitÃ© Ã  concevoir des workflows robustes, automatisÃ©s et rÃ©utilisables, qualitÃ©s essentielles pour un Data Engineer.

---

## ğŸ¯ Objectifs du projet
- **Automatiser** le traitement de donnÃ©es hÃ©tÃ©rogÃ¨nes (CSV, TSV, Fixed-Width).
- **Orchestrer** les tÃ¢ches avec Apache Airflow pour un pipeline fiable et maintenable.
- **Transformer** les donnÃ©es pour les rendre exploitables et prÃªtes Ã  lâ€™analyse.
- **Montrer** mes compÃ©tences pratiques en Data Engineering Ã  travers un projet concret.

---

## ğŸ› ï¸ Technologies utilisÃ©es
- **Python 3** : langage principal pour lâ€™ETL.
- **Apache Airflow** : orchestration et automatisation des tÃ¢ches.
- **Requests** : tÃ©lÃ©chargement des donnÃ©es.
- **Tarfile / CSV** : extraction et manipulation des fichiers.
- **Pendulum** : gestion des dates dans Airflow.

---

## ğŸ“‚ Structure du projet
